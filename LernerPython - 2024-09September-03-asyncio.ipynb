{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `asyncio`\n",
    "\n",
    "1. What is (and isn't?) `asyncio`\n",
    "2. How it works, using non-`asyncio` stuff\n",
    "3. Coroutines and tasks and `async def`\n",
    "4. Running coroutines and `await`\n",
    "5. Task groups\n",
    "6. Getting results (and exceptions)\n",
    "7. Task pools\n",
    "8. Retrieving URLs\n",
    "9. Chat server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The background\n",
    "\n",
    "Two related terms in programming:\n",
    "\n",
    "- Concurrency -- a more general term meaning that we can benefit from pieces of our program executing semi-independently, even if they're not truly indepent of one another\n",
    "- Parallelism -- running multiple parts of our program in parallel\n",
    "\n",
    "For example:\n",
    "- If I want read from 10 different files, then I might want to use parallelism -- each core on my system can read a different file\n",
    "- If I want to download data from 10 different URLs, this also might be possible with parallelism\n",
    "- If I have only one core, but I'm reading from 10 different files, I can still use concurrency -- because I can ask for data from one file, and while that data is coming to me, I can then turn to another file and ask for its data. This works because I know that it'll take a while for the data to come from any one of those files.\n",
    "\n",
    "Note that all of these examples are for problems that are I/O-bound, meaning that the bottleneck is basically that we're reading from disks/networks/etc.\n",
    "\n",
    "What if I wanted to perform a very big, difficult calculation like MD5 or SHA1, or bitcoin mining? Can I break any of those into pieces, and have them shared across CPUs? No. Those are CPU-bound problems. \n",
    "\n",
    "Over the years, we've had two main ways to get concurrency/parallelism in Python:\n",
    "- Multiprocessing -- allows us to start new processes, split our work across them, and even join the results together. The good news is that each process is indeed separate and runs in parallel. There are two problems -- first of all, each process has a lot of overhead. The other problem is that they are indeed totally separate processes, so we have to get the data to and from each of them.\n",
    "- Threading -- we can, in Python, start lots of new threads (many more than we can start processes). Threads have far lower overhead than processes, because we're inside of a single process. Because we're in a single process, that means we can share data.  But we're in a single process, and all of the threads run on one core. In Python, because of the GIL (global interpreter lock), only one thread can run at a time. We have concurrency, but we don't have parallelism.\n",
    "\n",
    "For  many years, despite the grumbling, we managed in the Python world to use both of these.\n",
    "\n",
    "As systems scaled up, this wasn't good enough. We wanted to be able to service a lot of requests from a server. We wanted to be able to work with lots of URLs on the Web. Neither was conducive to thousands or 10s of thousands of tasks at the same time.\n",
    "\n",
    "JavaScript works on servers via a system known as `nodejs`. It's *very* fast. It only has *one* process, and *one* thread. It does this using the \"reactor pattern\":\n",
    "- You have a list of functions\n",
    "- You iterate over that list, giving each function a chance to run\n",
    "- Every so often, the function says, \"I'm done for now,\" and gives up control of the CPU (and then the next function runs)\n",
    "- When a function completes, it removes itself from this list\n",
    "\n",
    "It turns out that this is *VERY* fast and efficient. \n",
    "\n",
    "That was the beginning of `asyncio`, which runs in a similar way.\n",
    "\n",
    "`asyncio` is cementing itself as a new form of concurrency in Python. Its called `asyncio` because it assumes that most of what it does will be with I/O, working with the network and/or filesystem, where you make a request and you know it'll take some time to get a result. During that time, we can let other functions run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the dumbest function in the world\n",
    "\n",
    "def myfunc():\n",
    "    return 1\n",
    "    return 2\n",
    "    return 3\n",
    "\n",
    "myfunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3           0 RESUME                   0\n",
      "\n",
      "  4           2 RETURN_CONST             1 (1)\n"
     ]
    }
   ],
   "source": [
    "import dis   # Python disassembler\n",
    "\n",
    "dis.dis(myfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's change one word in our function, from return to yield:\n",
    "\n",
    "def myfunc():\n",
    "    yield 1\n",
    "    yield 2\n",
    "    yield 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object myfunc at 0x10d2585c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc()    # calling the function doesn't execute it! Rather, it returns an object that expects to be put in a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = myfunc()   # this is a generator object, which impelments the iterator protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g)  # this runs the function through the next yield, and then the function goes to sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.gi_frame.f_lineno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.gi_frame.f_lineno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can create, using this, our own baby version of asyncio\n",
    "\n",
    "# we'll create a list \n",
    "# we'll put those generators on the list\n",
    "# we'll iterate through each generator, giving it a chance to run\n",
    "# when a generator is done (it raises StopIteration), we'll remove it from our list\n",
    "\n",
    "def mygen(id_number, maxnum):   \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
