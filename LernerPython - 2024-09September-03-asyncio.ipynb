{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `asyncio`\n",
    "\n",
    "1. What is (and isn't?) `asyncio`\n",
    "2. How it works, using non-`asyncio` stuff\n",
    "3. Coroutines and tasks and `async def`\n",
    "4. Running coroutines and `await`\n",
    "5. Task groups\n",
    "6. Getting results (and exceptions)\n",
    "7. Task pools\n",
    "8. Retrieving URLs\n",
    "9. Chat server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The background\n",
    "\n",
    "Two related terms in programming:\n",
    "\n",
    "- Concurrency -- a more general term meaning that we can benefit from pieces of our program executing semi-independently, even if they're not truly indepent of one another\n",
    "- Parallelism -- running multiple parts of our program in parallel\n",
    "\n",
    "For example:\n",
    "- If I want read from 10 different files, then I might want to use parallelism -- each core on my system can read a different file\n",
    "- If I want to download data from 10 different URLs, this also might be possible with parallelism\n",
    "- If I have only one core, but I'm reading from 10 different files, I can still use concurrency -- because I can ask for data from one file, and while that data is coming to me, I can then turn to another file and ask for its data. This works because I know that it'll take a while for the data to come from any one of those files.\n",
    "\n",
    "Note that all of these examples are for problems that are I/O-bound, meaning that the bottleneck is basically that we're reading from disks/networks/etc.\n",
    "\n",
    "What if I wanted to perform a very big, difficult calculation like MD5 or SHA1, or bitcoin mining? Can I break any of those into pieces, and have them shared across CPUs? No. Those are CPU-bound problems. \n",
    "\n",
    "Over the years, we've had two main ways to get concurrency/parallelism in Python:\n",
    "- Multiprocessing -- allows us to start new processes, split our work across them, and even join the results together. The good news is that each process is indeed separate and runs in parallel. There are two problems -- first of all, each process has a lot of overhead. The other problem is that they are indeed totally separate processes, so we have to get the data to and from each of them.\n",
    "- Threading -- we can, in Python, start lots of new threads (many more than we can start processes). Threads have far lower overhead than processes, because we're inside of a single process. Because we're in a single process, that means we can share data.  But we're in a single process, and all of the threads run on one core. In Python, because of the GIL (global interpreter lock), only one thread can run at a time. We have concurrency, but we don't have parallelism.\n",
    "\n",
    "For  many years, despite the grumbling, we managed in the Python world to use both of these.\n",
    "\n",
    "As systems scaled up, this wasn't good enough. We wanted to be able to service a lot of requests from a server. We wanted to be able to work with lots of URLs on the Web. Neither was conducive to thousands or 10s of thousands of tasks at the same time.\n",
    "\n",
    "JavaScript works on servers via a system known as `nodejs`. It's *very* fast. It only has *one* process, and *one* thread. It does this using the \"reactor pattern\":\n",
    "- You have a list of functions\n",
    "- You iterate over that list, giving each function a chance to run\n",
    "- Every so often, the function says, \"I'm done for now,\" and gives up control of the CPU (and then the next function runs)\n",
    "- When a function completes, it removes itself from this list\n",
    "\n",
    "It turns out that this is *VERY* fast and efficient. \n",
    "\n",
    "That was the beginning of `asyncio`, which runs in a similar way.\n",
    "\n",
    "`asyncio` is cementing itself as a new form of concurrency in Python. Its called `asyncio` because it assumes that most of what it does will be with I/O, working with the network and/or filesystem, where you make a request and you know it'll take some time to get a result. During that time, we can let other functions run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the dumbest function in the world\n",
    "\n",
    "def myfunc():\n",
    "    return 1\n",
    "    return 2\n",
    "    return 3\n",
    "\n",
    "myfunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3           0 RESUME                   0\n",
      "\n",
      "  4           2 RETURN_CONST             1 (1)\n"
     ]
    }
   ],
   "source": [
    "import dis   # Python disassembler\n",
    "\n",
    "dis.dis(myfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's change one word in our function, from return to yield:\n",
    "\n",
    "def myfunc():\n",
    "    yield 1\n",
    "    yield 2\n",
    "    yield 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object myfunc at 0x10d2585c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc()    # calling the function doesn't execute it! Rather, it returns an object that expects to be put in a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = myfunc()   # this is a generator object, which impelments the iterator protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g)  # this runs the function through the next yield, and then the function goes to sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.gi_frame.f_lineno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.gi_frame.f_lineno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 0\n",
      "2: 0\n",
      "3: 0\n",
      "1: 1\n",
      "2: 1\n",
      "3: 1\n",
      "1: 2\n",
      "2: 2\n",
      "3: 2\n",
      "1: 3\n",
      "2: 3\n",
      "1: 4\n",
      "2: 4\n",
      "2: 5\n",
      "2: 6\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# we can create, using this, our own baby version of asyncio\n",
    "\n",
    "# we'll create a list \n",
    "# we'll put those generators on the list\n",
    "# we'll iterate through each generator, giving it a chance to run\n",
    "# when a generator is done (it raises StopIteration), we'll remove it from our list\n",
    "\n",
    "def mygen(id_number, maxnum):   # we'll take 2 arguments, the ID number and the number we'll go up to \n",
    "    for i in range(maxnum):\n",
    "        yield f'{id_number}: {i}'\n",
    "\n",
    "g1 = mygen(1, 5)   # id 1, up to 5\n",
    "g2 = mygen(2, 7)   # id 2, up to 7\n",
    "g3 = mygen(3, 3)   # id 3, up to 3\n",
    "\n",
    "generators = [g1, g2, g3]\n",
    "\n",
    "while generators:   # so long as this list is non-empty\n",
    "    for one_g in generators:\n",
    "        try:\n",
    "            print(next(one_g))   # ask the current generator for its next value, and print it\n",
    "        except StopIteration:\n",
    "            generators.remove(one_g)  # if we got to the end of a generator, remove it from our list\n",
    "\n",
    "print('Done!')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping this to `asyncio`\n",
    "\n",
    "- In `asyncio`, we don't define regular functions. Rather, we define `async def` functions. Just as generator functions, when we run them, give us generator objects, async def functions return *coroutines*. You don't run a coroutine directly. Rather, you put it on the event loop, where it gets multiple chances to run... until it ends.\n",
    "- The event loop is a combination of a list and a `while` loop. So long as there are tasks on the loop, `asyncio` will run them, one at a time, giving each a chance to run for a bit.\n",
    "- Instead of `yield` in generators, in `asyncio` we use a term called `await`. This means two things at once: First, that we're waiting for a value from something that might take a while. Second: While we're waiting, we're willing to go to sleep, a la `yield`.\n",
    "\n",
    "It used to be, in older `asyncio` usage, that you would explicitly create or ask for the event loop, and you would put things directly on it. This is no longer considered OK. That's considered low-level `asyncio` usage.\n",
    "\n",
    "If a coroutine doesn't have any `await` statements, then it runs all at once, never pausing, and never giving anyone else a chance to run. \n",
    "\n",
    "We've basically moved from the world of preemptive multitasking (with threads and multiprocessing) back 40 years to cooperative multitasking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How we'll write code in `asyncio`\n",
    "\n",
    "1. We structure our code as generator-like functions, which we'll execute and get \"coroutines\" from. We'll use `async def` to do this.\n",
    "2. We'll add our coroutines to the event loop.\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def hello():\n",
    "    print('Hello!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(myfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:              myfunc\n",
      "Filename:          /var/folders/rr/0mnyyv811fs5vyp22gf4fxk00000gn/T/ipykernel_76060/1889638504.py\n",
      "Argument count:    0\n",
      "Positional-only arguments: 0\n",
      "Kw-only arguments: 0\n",
      "Number of locals:  0\n",
      "Stack size:        2\n",
      "Flags:             OPTIMIZED, NEWLOCALS, GENERATOR\n",
      "Constants:\n",
      "   0: None\n",
      "   1: 1\n",
      "   2: 2\n",
      "   3: 3\n"
     ]
    }
   ],
   "source": [
    "dis.show_code(myfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:              hello\n",
      "Filename:          /var/folders/rr/0mnyyv811fs5vyp22gf4fxk00000gn/T/ipykernel_76060/1347416487.py\n",
      "Argument count:    0\n",
      "Positional-only arguments: 0\n",
      "Kw-only arguments: 0\n",
      "Number of locals:  0\n",
      "Stack size:        3\n",
      "Flags:             OPTIMIZED, NEWLOCALS, COROUTINE\n",
      "Constants:\n",
      "   0: None\n",
      "   1: 'Hello!'\n",
      "Names:\n",
      "   0: print\n"
     ]
    }
   ],
   "source": [
    "dis.show_code(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object hello at 0x10dd52740>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't run coroutines directly!\n",
    "\n",
    "- We add them to the event loop\n",
    "- `asyncio`, when it gets to our coroutine, will give it a chance to run through the next `await`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: `async` tasks\n",
    "\n",
    "1. Define three coroutine functions:\n",
    "    - `up` takes a single integer, `maximum`, and returns a string saying `up` and the current number. With each iteration, it'll go from 0 up to `maximum`.\n",
    "    - `down` is the same thing, but starts with `maximum`, and goes down to 0.\n",
    "    - `powers` takes a number, `n`, and returns (with each iteration) `n` to a new power up to 7 (i.e., `n ** 7`).\n",
    "2. Write a `main` routine that schedules them all on the event loop as tasks\n",
    "3. `await` all of them, and we should see their results intertwined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Task groups\n",
    "\n",
    "1. Write an `async def` that takes a filename as an argument, and returns a tuple whose first element is the filename, and whose second element is a dictionary whose keys are the characters in the file, and whose values are integers describing how many times each character appears. This `async def` should iterate over the lines of the file, pausing (with `asyncio.sleep`) between each line.\n",
    "2. From `main`, iterate over the names of several files and run our function on each of those files, each in a separate task.\n",
    "3. Iterate over each returned value -- filename and dict, and print them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
